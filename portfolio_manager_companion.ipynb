{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: notify if ollama server is running with model loaded\n",
    "import subprocess, os\n",
    "from llama_index.core import Document\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.llms.openai import OpenAI as LOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('/workspace/repos/agentic-ai/.env')\n",
    "\n",
    "model_name, ctx_len = \"llama3.1:8b-instruct-q8_0\", 128000\n",
    "# model_name, ctx_len = \"qwen2.5:3b-instruct-q8_0\", 128000\n",
    "# ollama pull hf.co/mradermacher/SaulLM-54B-Instruct-i1-GGUF:Q6_K\n",
    "# ollama pull hf.co/mradermacher/SaulLM-54B-Instruct-i1-GGUF:Q4_K_M\n",
    "# ollama pull hf.co/bartowski/Llama-3.1-Nemotron-70B-Instruct-HF-GGUF:Q4_K_M\n",
    "\n",
    "\n",
    "if \"gpt-4o\" in model_name:\n",
    "    openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
    "    \n",
    "    print(f\"Using OpenAI {model_name}...\")\n",
    "    llm = LOpenAI(model=model_name, max_tokens=8000)\n",
    "else:\n",
    "    subout = subprocess.run(['ollama', 'list'], capture_output=True, text=True)\n",
    "    if model_name in subout.stdout:\n",
    "        print('Model loaded...')\n",
    "    else:\n",
    "        try: \n",
    "            print(\"Pulling Ollama model...\")\n",
    "            sub_out = subprocess.run(['ollama', 'pull', model_name], capture_output=True, text=True)\n",
    "        except Exception as e: \n",
    "            print(f\"Error pulling model: Is the Ollama server running?\\n{e}\")\n",
    "    \n",
    "    system_prompt = \"You are training an new Portfolio Manager of a hedgefund.\"\n",
    "    additional_kwargs = {\"num_predict\": 1000}\n",
    "    llm = Ollama(model=model_name, url=\"http://127.0.0.1:11434\", context_window=ctx_len, model_type=\"chat\", is_function_calling_model=True, \n",
    "                 request_timeout=4000.0, additional_kwargs=additional_kwargs, keep_alive=0) #, system_prompt=system_prompt)\n",
    "    print(llm.metadata)\n",
    "\n",
    "# Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import Document\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('/workspace/repos/project-mayhem/.env')\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "llama_api_key = os.getenv(\"LLAMA_API_KEY\")\n",
    "\n",
    "def extract_text_from_pdf(pdf_urls, llama_api_key, llamaparse_kwargs={}, save_json_path=None):\n",
    "    \n",
    "    parser = LlamaParse(api_key=llama_api_key, **llamaparse_kwargs)\n",
    "    \n",
    "    documents = []\n",
    "    for pdf in pdf_urls:\n",
    "        print('processing pdf:', pdf)\n",
    "        documents += parser.load_data(pdf)\n",
    "\n",
    "    if save_json_path:\n",
    "        with open(save_json_path, \"r\") as f:\n",
    "            result = json.load(f)\n",
    "            documents.append(Document(text=result['text']))\n",
    "    \n",
    "    return documents\n",
    "\n",
    "pages_to_extract = \"\"\n",
    "beginning_of_chapter = 21\n",
    "end_of_chapter = 54 # 644\n",
    "for i in range(beginning_of_chapter,end_of_chapter):\n",
    "    if i == end_of_chapter - 1:\n",
    "        pages_to_extract += str(i)\n",
    "    else:\n",
    "        pages_to_extract += str(i) + \",\"\n",
    "principles_of_finance = \"https://assets.openstax.org/oscms-prodcms/media/documents/PrinciplesofFinance-WEB.pdf\"\n",
    "documents = extract_text_from_pdf([principles_of_finance], llama_api_key, llamaparse_kwargs={\"split_by_page\": False, \"target_pages\": pages_to_extract}, save_json_path=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "SemanticSplitterNodeParser?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/workspace/data/principles_of_finance.json\", \"w\") as f:\n",
    "    json.dump([d.text for d in documents], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/workspace/data/principles_of_finance.json\", \"r\") as f:\n",
    "    documents = [Document(text=text) for text in json.load(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "# OLLAMA_HOST=\"http://127.0.0.1:11436\" ollama start \n",
    "uvu_policy_manual_embed_model = OllamaEmbedding(\n",
    "    model_name=\"llama3.2:1b-instruct-q8_0\", # other embed option \"bge-m3\"\n",
    "    # model_name=\"bge-m3\", # other embed option \"bge-m3\"\n",
    "    base_url=\"http://127.0.0.1:11436\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0, \"keep_alive\": 0},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "\n",
    "splitter = SemanticSplitterNodeParser(buffer_size=1, embed_model=embed_model, include_metadata=True)\n",
    "nodes = splitter.get_nodes_from_documents(documents, show_progress=True)\n",
    "print(f\"Number of nodes: {len(nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "data_path = \"microsoft/orca-agentinstruct-1M-v1\"\n",
    "dataset = load_dataset(data_path)\n",
    "orca_keys = list(dataset.keys())\n",
    "\n",
    "okey = orca_keys[1]\n",
    "teststr = dataset[okey][0]['messages']\n",
    "# Convert the string to a list of dictionaries\n",
    "list_of_dicts = json.loads(teststr)\n",
    "\n",
    "print(okey)\n",
    "list_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instruction_prompts import all_questions\n",
    "from parse_instruction_output import all_parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = list(all_questions.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.complete(all_questions['word_definition'].format(financial_text=nodes[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=\"\"\"Importance of Macroeconomic Variables in Financial Markets\n",
    "To make financial forecasts, managers need good information to understand the relationship among several\n",
    "economic variables. Working from small to large, sales forecasts estimate the likely price and quantity of\n",
    "goods sold. In doing so, the forecaster will consider local, regional, state, national, and international economic\n",
    "conditions. Inflation is an important macroeconomic variable that influences prices. Every quarter, financial\n",
    "information hubs, such as the Wall Street Journal (WSJ), and government agencies and regulatory bodies, such\n",
    "as the Treasury Department and the Federal Reserve, release estimates about expected and current inflation.\n",
    "This information informs policy makers how to adjust the money supply to meet target objectives. Financial\n",
    "forecasters pay close attention to current and expected interest rates, as they have a fundamental impact on\n",
    "the cost of raising money and determining the required rate of return for investment.\n",
    "The unemployment rate helps inform financial forecasters about the expected cost of labor and the ability of\n",
    "employers to hire people if a firm plans to increase the production of goods or services. The stock market is a\n",
    "forward-looking macroeconomic variable and measures investor expectations about future cash flows and\n",
    "economic growth. Political economic variables such as changes in regulation or tax policy can also affect\n",
    "forecasting models.\n",
    "LINK TO LEARNING\n",
    "Politics and Stock Markets\n",
    "Politics and stock market returns make for heated conversations. Who can run the country’s economic\n",
    "system better, Republicans or Democrats? Presidents often take the credit or blame for overall economic\n",
    "performance even though their actual influence is less than you might think. See this fun comparison chart\n",
    "(https://openstax.org/r/macrotrends-net) of political economic performance that measures stock market\n",
    "returns by each administration going back to President Warren Harding in 1920. Who had the highest\n",
    "overall increase in the market? What president in the 21st century oversaw an overall decline in the market?\n",
    "Just to get things going, who had better overall market returns after four years in office, Donald Trump or\n",
    "Barack Obama?\n",
    "Each of the variables we have identified—inflation, interest rates, unemployment, economic growth, the stock\n",
    "market, and government fiscal policy—are macroeconomic factors. They are beyond the scope and influence\n",
    "of individual firms, but combined, they play a critical role in establishing the market in which firms compete. A\n",
    "better understanding of the interaction of these macro variables with each other and with individual micro or\n",
    "firm-specific variables can only strengthen financial forecasting and management decision-making.\n",
    "CONCEPTS IN PRACTICE\n",
    "Here, There, and Everywhere: Where Did Your iPhone Come From?\n",
    "How do international macroeconomic factors affect investment decisions for businesses and individuals?\n",
    "Foreign investment adds risk and potential return to the decision-making process. Macroeconomic factors\n",
    "such as different inflation rates, unexpected changes in currency exchange rates, and mismatched\n",
    "economic growth all add to the uncertainty of making investments abroad. Just as important are\n",
    "government regulations limiting pollution, exploitation of precious minerals, labor laws, and tariffs. Toss in\n",
    "a pandemic, and a bottleneck or two, and suddenly international macroeconomic factors can affect almost\n",
    "every aspect of commerce and international trade.\n",
    "24 1 • Introduction to Finance\n",
    "Access for free at openstax.org\n",
    "For example, how far did your new iPhone travel before it got into your hands? Apple is an American\n",
    "company headquartered in Cupertino, California, and worth over $2 trillion.8 However, your phone may\n",
    "have visited as many as six continents before it reached you. Each location touched by the Apple corporate\n",
    "hand requires an understanding of the financial impact on the product cost and a comparison with\n",
    "alternative designs, resources, suppliers, manufacturers, and shippers. This is where finance can get really\n",
    "fun!\n",
    "Relationship between Microeconomics and Macroeconomics\n",
    "In the parable, a group of blind people happen upon an elephant for the first time, and they each touch one\n",
    "part—but one part only—of the elephant. Subsequently, when they each describe what they have discovered,\n",
    "the descriptions are vastly different. The group's members become upset, accusing one another of inaccurate\n",
    "descriptions or worse. The parable demonstrates how individuals can make absolute truths from their own\n",
    "limited and subjective information. Financial decision makers run a similar risk, if they choose to recognize\n",
    "only their own findings and ignore other microeconomic or macroeconomic information and the interaction of\n",
    "these factors.\n",
    "A common view to understanding economics states that macroeconomics is a top-down approach and\n",
    "microeconomics is a bottom-up approach. Financial decision makers need to see both the forest and the\n",
    "individual trees to chart a course and move toward a strategic objective. They need both the macro data, so\n",
    "important for strategic thinking, and the micro data, required for tactical movement. For example, the national\n",
    "rate of unemployment may not have been much help when Bacon Signs was searching for skilled laborers\n",
    "who could form neon signs. However, the unemployment rate helped inform the company about the\n",
    "probability of demand for new businesses and the signs they would need.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "# OLLAMA_HOST=\"http://127.0.0.1:11436\" ollama start \n",
    "embed_model = OllamaEmbedding(\n",
    "    model_name=\"llama3.2:1b-instruct-q8_0\", # other embed option \"bge-m3\"\n",
    "    # model_name=\"bge-m3\", # other embed option \"bge-m3\"\n",
    "    base_url=\"http://127.0.0.1:11436\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0, \"keep_alive\": 0},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [Document(text=doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "\n",
    "splitter = SemanticSplitterNodeParser(buffer_size=1, embed_model=embed_model, include_metadata=True)\n",
    "nodes = splitter.get_nodes_from_documents(documents, show_progress=True)\n",
    "print(f\"Number of nodes: {len(nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "task_list = {\n",
    "    \"antonym_relation\":(\"Generate a question asking for an antonym of a word in the given text. Provide the answer.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"one_sentence_description\":(\"Provide a one-sentence description of the given text.\", \"Output:\\nReasoning:\\n\"),\n",
    "    \"interview_question_answering\":(\"Generate an interview question and answer based on the given text.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"idiom_meaning\":(\"Generate an idiom from the given text.\", \"Output:\\nReasoning:\\n\"),\n",
    "    \"explain_behavior\":(\"Generate human behavior in relation to the provided text, and provide an explanation of the behavior as the answer.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"question_answering_generation_from_facts\":(\"Generate a question and answer pair based on the given text.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"analogy_completion_given_3_of_4_words\":(\"Generate an analogy from the given text. Leave one word blank. Provide the missing word as the answer.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"explain_complex_concept_to_someone_without_background\":(\"Generate an explanation of a complex concept from the given text, as if explaining it to someone without any background knowledge.\", \"Output:\\nReasoning:\\n\"),\n",
    "    \"fun_math_question\":(\"Generate a fun math question, with answers, based on the given text.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"perfect_and_exact_numbers\":(\"Generate a question that requires the use of exact numbers, based on the given text. Provide the answer.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"story_composition\":(\"Generate a story based on the given text.\", \"Output:\\nReasoning:\\n\"),\n",
    "    \"solving_equation\":(\"Generate an equation to solve, with its answer, based on the given text.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"synonym_generation\":(\"Generate a question asking for a synonym for a word in the given text. Provide the answer.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"grammar_error_correction\":(\"Select a few sentences from the given text and rewrite them to include grammar and spelling mistakes. Provide the original sentences\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"correct_misspelling\":(\"Select a few sentences from the given text and rewrite them to include spelling mistakes. Provide the original sentences\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"math_word_problem_with_reasoning\":(\"Generate a math word problem with reasoning and answer based on the given text.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"unethical_behavior\":(\"Generate an example of unethical behavior based on the given text.\", \"Output:\\nReasoning:\\n\"),\n",
    "    \"text_to_conversation\":(\"Generate a conversation based on the given text.\", \"Output:\\nReasoning:\\n\"),\n",
    "    \"metaphor_for_a_situation\":(\"Generate a metaphor for a situation based on the given text.\", \"Output:\\nReasoning:\\n\"),\n",
    "    \"better_word_choice\":(\"Generate a question that asks for a better word choice for a word in the given text. Provide the answer.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"sentence_with_specified_ending\":(\"Specify an ending to a sentence, and generate a sentence with the specified ending based on the given text.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"word_definition\":(\"Extract a word from the given text and generate a definition for the word.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"text_summarization\":(\"Generate a summary of the given text.\", \"Output:\\nReasoning:\\n\"),\n",
    "    \"fill_in_the_masked_word\":(\"Generate a sentence with a masked word based on the given text. Provide the masked word as the answer.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),    \n",
    "    \"writing_article_from_outline\":(\"Write an outline for an article based on the given text.\", \"Output:\\nReasoning:\\n\"),\n",
    "    \"socratic_questioning\":(\"Generate a series of Socratic questions based on the given text.\", \"Output:\\nReasoning:\\n\"),\n",
    "    \"paper_title_generation\":(\"Generate a title for a paper based on the given text.\", \"Output:\\nReasoning:\\n\"),\n",
    "    \"start_professional_conversation_from_text\":(\"Generate the start of a professional conversation based on the given text.\", \"Output:\\nReasoning:\\n\"),\n",
    "    \"numerical_question_answering\":(\"Generate a numerical based question and answer based on the given text.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"ethical_and_behavioral_interview_questions\":(\"Generate ethical and behavioral interview questions based on the given text. Provide the answer.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"meaning_to_phrase\":(\"Generate a phrase that conveys the meaning of the given text.\", \"Output:\\nReasoning:\\n\"),\n",
    "    \"paraphrase_a_paragraph\":(\"Paraphrase a paragraph based on the given text.\", \"Output:\\nReasoning:\\n\"),\n",
    "    \"ner_fill-in-the-blank\":(\"Generate a fill in the blank question with the named entities as answers from the given text.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"explain_concept_like_i_am_5\":(\"Explain a concept based on the given text as if you are explaining it to a 5-year-old.\", \"Output:\\nReasoning:\\n\"),\n",
    "    \"solving_math_problem_with_intermediate_steps\":(\"Generate a math problem with intermediate steps and answer based on the given text.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"ethical_dilemma_based_on_text\":(\"Generate an ethical dilemma based on the given text. Provide a solution.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"fill_in_the_blank\":(\"Generate a fill in the blank question based on the given text. Provide the answer.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"paraphrasing_classification_for_two_sentences\":(\"Based on the given text, generate two sentences that are either the same paraphrased versions of the original text, or different paraphrased versions of the original text. Randomly select whether the sentences are the same or not. Provide the classification.\", \"Output 1:\\nOutput 2:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"ethicality_judgement\":(\"Generate a question that asks for the ethicality of a situation based on the given text. Provide the answer.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"topic_classification\":(\"Generate a question that asks for the topic of the given text. Provide the answer.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"fact_verification\":(\"Generate a question that asks for the verification of a fact based on the given text. Provide the answer.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"most_relevant_passage_from_user_query\":(\"Generate a query from the given text and ask for the most relevant passage based on the query as the answer.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"support_classification_of_text\":(\"Given the text, generate a claim that either supports the text or does not support the text. Provide the classification.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "    \"fact_checking_based_on_knowledge\":(\"Generate a question that asks for the fact-checking of a statement based on the given text. Provide the answer.\", \"Output:\\nAnswer:\\nReasoning:\\n\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_prompt = \"\"\"You are a prompt engineering assistant. Your task is to create high-quality prompt templates for language models that will generate synthetic training data for the task: '{task_description}'. The purpose of these prompt templates is to instruct the language model to generate examples that match the specified output format. Your prompt should include detailed instructions and reasoning for the language model to follow. Here is the full description of the task:\n",
    "Full Task Description:\n",
    "{full_description}\n",
    "\n",
    "When designing a prompt template:\n",
    "\n",
    "1. Include these three user provided string format parameters in the prompt template:\n",
    "- {{context_text}}: Input text to base generations on\n",
    "- {{special_instructions}}: Any specific requirements\n",
    "- {{num_generate}}: Number of examples to generate\n",
    "\n",
    "2. Include these sections:\n",
    "Task Overview:\n",
    "[Explanation derived from task_description and full_description]\n",
    "\n",
    "Input Context:\n",
    "{{context_text}}\n",
    "\n",
    "Special Instructions:\n",
    "{{special_instructions}}\n",
    "\n",
    "Generation Instructions:\n",
    "Generate {{num_generate}} examples that match the specified output format.\n",
    "For each example:\n",
    "1. Use the input context to generate the example\n",
    "2. Provide step-by-step reasoning for each generation\n",
    "3. Follow the exact format output as follows:\n",
    "{output_format}\n",
    "\n",
    "{response_guidelines}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "of='Output: [Question with context]\\nAnswer: [The answer to the generated question]\\nReasoning: [A step-by-step explanation justifying the generation]\\n'\n",
    "response_guidelines=\"\"\"Response Guidelines:\n",
    "- Do not use Markdown or HTML formatting\n",
    "- Do not mention the existence of the text Input Context\n",
    "- Each generation must include explicit reasoning\n",
    "- Follow the exact output format specified\n",
    "- Stay consistent with task objectives\n",
    "- Focus on realistic, high-quality examples\n",
    "- Only output the prompt template without any pretext information, meta-commentary or formatting\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task= \"antonym_relation\"\n",
    "task='paraphrasing_classification_for_two_sentences'\n",
    "# task_gen_prompt = llm.complete(meta_prompt.format(task_description=task, full_description=task_list[task][0], output_format=task_list[task][1]))\n",
    "task_gen_prompt = llm.complete(meta_prompt.format(task_description=task, full_description=task_list[task][0], output_format=task_list[task][1], response_guidelines=response_guidelines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(task_gen_prompt.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.complete(task_gen_prompt.text.format(context_text=nodes[0].text, special_instructions=\"\", num_generate=3)+f\"\\n\\n{response_guidelines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_output(input_text):\n",
    "    lines = input_text.split('\\n')\n",
    "    outputs = []\n",
    "    answer = \"\"\n",
    "    reasoning = \"\"\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.startswith(\"Output:\") or line.startswith(\"Output \"):\n",
    "            outputs.append(line.split(\":\", 1)[1].strip())\n",
    "        elif line.startswith(\"Answer:\"):\n",
    "            answer = line[len(\"Answer:\"):].strip()\n",
    "        elif line.startswith(\"Reasoning:\"):\n",
    "            reasoning = line[len(\"Reasoning:\"):].strip()\n",
    "    \n",
    "    return outputs, answer, reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=\"\"\"Here are three examples that match the specified output format:\n",
    "\n",
    "\n",
    "**Example 1**\n",
    "\n",
    "Output: To make financial forecasts, managers need good information to understand the relationship among several economic variables.\n",
    "Answer: Different\n",
    "Reasoning: The two sentences are different paraphrased versions of the original text. While both sentences convey the importance of understanding economic relationships for financial forecasting, they use distinct wording and phrasing.\n",
    "\n",
    "\n",
    "**Example 2**\n",
    "\n",
    "Output: Every quarter, financial information hubs release estimates about expected and current inflation.\n",
    "Answer: Different\n",
    "Reasoning: The two sentences are different paraphrased versions of the original text. Although both sentences mention quarterly releases of inflation data, they use distinct language and formatting.\n",
    "\n",
    "\n",
    "**Example 3**\n",
    "\n",
    "Output: \n",
    "Financial forecasters pay close attention to current and expected interest rates because they significantly impact the cost of raising money.\n",
    "Answer: Different\n",
    "Reasoning: The two sentences are different paraphrased versions of the original text. While both sentences discuss the importance of interest rates for financial forecasting, they use distinct wording and phrasing to convey this idea.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_output(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def parse_output(output): \n",
    "    output = output.replace('', '') \n",
    "    pattern = re.compile(r\"Output(?: \\d)?:\\s(.?)\\n?\\n?Answer:\\s(.?)\\n?\\n?Reasoning:\\s(.*?)(?=\\n?\\n?Output|\\Z)\", re.DOTALL)\n",
    "    matches = pattern.findall(output) \n",
    "    parsed_examples = [{'output':match[0].strip(), 'answer':match[1].strip(), 'reasoning':match[2].strip()} for match in matches] \n",
    "    return parsed_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_output(output):\n",
    "    # Define the pattern to match \"Output 1\" and optionally \"Output 2\"\n",
    "    pattern = r\"Output 1: (.*?)\\n(?:Output 2: (.*?))?\\n\"\n",
    "    match = re.search(pattern, output, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        output1 = match.group(1)\n",
    "        output2 = match.group(2) if match.group(2) else None\n",
    "        return output1, output2\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Example usage\n",
    "test = \"Output 1: Value1\\nOutput 2: Value2\\n\"\n",
    "output1, output2 = parse_output(test)\n",
    "print(f\"Output 1: {output1}, Output 2: {output2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
