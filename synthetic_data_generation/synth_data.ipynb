{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: notify if ollama server is running with model loaded\n",
    "import subprocess, os\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.llms.openai import OpenAI as LOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('/workspace/repos/deep_fund/.env')\n",
    "\n",
    "# model_name, ctx_len = \"llama3.1:8b-instruct-q8_0\", 128000\n",
    "model_name, ctx_len = \"qwen2.5:3b-instruct-q8_0\", 128000\n",
    "# ollama pull hf.co/mradermacher/SaulLM-54B-Instruct-i1-GGUF:Q6_K\n",
    "# ollama pull hf.co/mradermacher/SaulLM-54B-Instruct-i1-GGUF:Q4_K_M\n",
    "\n",
    "if \"gpt-4o\" in model_name:\n",
    "    openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
    "    \n",
    "    print(f\"Using OpenAI {model_name}...\")\n",
    "    llm = LOpenAI(model=model_name, max_tokens=8000)\n",
    "else:\n",
    "    subout = subprocess.run(['ollama', 'list'], capture_output=True, text=True)\n",
    "    if model_name in subout.stdout:\n",
    "        print('Model loaded...')\n",
    "    else:\n",
    "        try: \n",
    "            print(\"Pulling Ollama model...\")\n",
    "            sub_out = subprocess.run(['ollama', 'pull', model_name], capture_output=True, text=True)\n",
    "        except Exception as e: \n",
    "            print(f\"Error pulling model: Is the Ollama server running?\\n{e}\")\n",
    "    \n",
    "    addtion_kwargs = {\"max_new_tokens\": 8000}\n",
    "    system_prompt = \"You create datasets for instruction fine-tuning for large language models.\"\n",
    "    llm = Ollama(model=model_name, url=\"http://127.0.0.1:11434\", context_window=ctx_len, model_type=\"chat\", is_function_calling_model=False, \n",
    "                 request_timeout=4000.0, additional_kwargs=addtion_kwargs, system_prompt=system_prompt, keep_alive=0)\n",
    "    print(llm.metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/yizhongw/self-instruct/blob/main/data/seed_tasks.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the input into \"clean format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Why It Matters\n",
    "One of the single most important concepts in the study of finance is the time value of money (TVM). This\n",
    "concept puts forward the idea that a dollar received today is worth more than, and therefore preferable to, a\n",
    "dollar received at some point in the future. The three primary reasons for this are that (1) money received now\n",
    "can be saved or invested now and earn interest or a return, resulting in more money in the future; (2) any\n",
    "promise of future payments of cash will always carry the risk of default; and (3) it is simple human nature for\n",
    "people to prefer making their purchases of goods and services in the present rather than waiting to make\n",
    "them at some future time.\n",
    "For this reason, it is important to incentivize people to give up their present consumption patterns by offering\n",
    "them greater value in the future. Based on the concept of TVM, it can be said that a dollar was worth more to\n",
    "us, and thus carried more value, yesterday than it is to us today. It also then follows that a dollar in our\n",
    "possession right now carries a greater value for us than a dollar we might receive tomorrow or at some other\n",
    "point in the future.\n",
    "The entire concept of the time value of money is particularly important because it allows savers and investors\n",
    "to make better-informed decisions about what to do with their money. TVM can help a person understand\n",
    "which option may be best based on the critical factors of overall risk, rates of interest, inflation, and return.\n",
    "TVM can also be used to help a person understand how much money they’ll need to save in an interestbearing account in order to reach a desired financial goal, such as saving $50,000 in 10 years in an account that earns 4% compound interest each year. TVM is the key underlying principle of such important financial\n",
    "analytical activities as retirement planning, corporate capital project evaluation, and even deciding on your\n",
    "Time Value of Money I: Single Payment Value\n",
    "7 • Why It Matters 191\n",
    "own personal investments and bank accounts.\n",
    "If the main concept behind the TVM is that a specific amount of money in hand now is worth more today than\n",
    "that same amount of money will be worth tomorrow, you might think that a person would be better off\n",
    "spending their money now rather than saving it for later use. However, we know that this is not always the\n",
    "case. Sometimes it is simply a better idea to save your money. While inflation can have the effect of making a\n",
    "dollar worth less tomorrow than it is worth today, the positive effect of compound interest works in favor of\n",
    "savers and investors.\n",
    "7.1 Now versus Later Concepts\n",
    "Learning Outcomes\n",
    "By the end of this section, you will be able to:\n",
    "• Explain why time has an impact on the value of money.\n",
    "• Explain the concepts of future value and present value.\n",
    "• Explain why lump sum cash flow is the basis for all other cash flows.\n",
    "How and Why the Passage of Time Affects the Value of Money\n",
    "The concept of the time value of money (TVM) is predicated on the fact that it is possible to earn interest\n",
    "income on cash that you decide to deposit in an investment or interest-bearing account. As times goes by,\n",
    "interest is earned on amounts you have invested (present value), which effectively means that time will add\n",
    "value (future value) to your savings. The longer the period of time you have your money invested, the more\n",
    "interest income will accrue. Also, the higher the rate of interest your account or investment is earning, again,\n",
    "the more your money will grow.\n",
    "Understanding how to calculate values of money in the present and at different points in the future is a key\n",
    "component of understanding the material presented in this chapter—and of making important personal\n",
    "financial decisions in your future (see Figure 7.2).\n",
    "Figure 7.2 The Time Value of Money It is better to be paid today, or you will lose out on the money you would have earned in\n",
    "interest.\n",
    "The Lump Sum Payment or Receipt\n",
    "The most basic type of financial transaction involves a simple, one-time amount of cash, which can be either a\n",
    "receipt (inflow) or a payment (outflow). Such a one-time transaction is typically referred to as a lump sum. A\n",
    "lump sum consists of a one-off cash flow that occurs at any single point in time, present or future. Because it is\n",
    "always possible to dissect more complex transactions into smaller parts, the lump sum cash flow is the basis\n",
    "on which all other types of cash flow are treated.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core.postprocessor import LLMRerank\n",
    "from rag_utils import create_llama_vector_index_rag\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "documents = None\n",
    "\n",
    "# OLLAMA_HOST=\"http://127.0.0.1:11436\" ollama start \n",
    "embed_model = OllamaEmbedding(\n",
    "    # model_name=\"llama3.2:1b-instruct-q8_0\", # other embed option \"bge-m3\"\n",
    "    model_name=\"bge-m3\", # other embed option \"bge-m3\"\n",
    "    base_url=\"http://127.0.0.1:11436\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0},\n",
    ")\n",
    "\n",
    "policy_vector_index = create_llama_vector_index_rag(llm, \n",
    "                                                    embed_model, \n",
    "                                                    documents=documents,\n",
    "                                                    persist_dir=\"/workspace/data/uvu_lit/vector_idx_poicy_manual\",\n",
    "                                                    vector_store_kwargs={\"chunk_size\": 500, \"chunk_overlap\": 30}\n",
    ")\n",
    "\n",
    "policy_query_engine = policy_vector_index.as_query_engine(\n",
    "    llm=llm,\n",
    "    similarity_top_k=10,\n",
    "    node_postprocessors=[\n",
    "        LLMRerank(\n",
    "            llm=llm,\n",
    "            choice_batch_size=5,\n",
    "            top_n=3,\n",
    "        )\n",
    "    ],\n",
    "    # see https://github.com/run-llama/llama_index/blob/f7c5ee5efbb6172e819f26d1705fcdf6114b11a3/llama-index-core/llama_index/core/response_synthesizers/type.py#L4\n",
    "    response_mode=\"tree_summarize\", # \"accumulate\", \"compact_accumulate\", \"compact\", \"simple_summarize\", \"tree_summarize\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Catastrophic forgetting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
